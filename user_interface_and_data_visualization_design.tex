\resetdatestamp

\chapter{User Interface and Data Visualization Design}

\section{General History}

The concerns of user interface designers have changed considerably since people first started interacting with programmable digital computers for processing, storing, and retrieving information. 

The first interfaces often depended on punch cards and paper tape as control mechanisms and line printers for output and program feedback. On machines used during the 1950s and 1960s, in order to input a program and a dataset into a computer, first one prepares a deck of punched cards using a typewriter-like machine, then one feeds the deck to the computer \cite{oshistory2011}. Optionally on some machines, one can mount reels of magnetic tape that store oft-used or previously generated datasets or compiled software. On these early machines, a particular program being run from a deck of punch cards would occupy the resources of the entire computer. Any hardware devices required by a particular program like punch card readers and line printers had to be handled completely by the program. 

\emph{Operating systems} development grew out of the growing complexity of computer systems involving many cooperating devices and the mirrored growth of the complexity of the programs that were written for them. It makes little sense for a user of a machine to write basic operating software for interfacing with standardized perhipheral devices everytime they want to run a program on such a machine. Especially, since any user of a computer during the 1960s likely needed to enter a queue to reserve time to run their program on a single shared machine and any time wasted debugging low-level interactions with input and output devices was surely frusterating. Predictably, machines begain appearing with libraries of code that took care of low-level control and provided easier access to input and output devices as always resident services. This collection of software that is permenantly resident on a machine became known as a \emph{batch monitor} \cite{os2000}. A user's program could link to these preloaded libraries without including the operating logic explicitly within their own program code. This shift is often cited as the genesis of the modern operating system.

In addition to providing access to input/output devices, the monitor often provided services to perform error checking on user submitted programs and generating useful feedback to the user concerning the progress of execution of a user program. The idea of generating "useful" feedback, and what that might mean, can be understood as the first instance of an explicitly designed user interface \cite{unix2008}.

Command-line interfaces are the next step in the evolution of computer interfaces and the link between batch systems of the 1950s and what would be recognized as a graphical user interface today. With continual, steady reduction of the amount of time needed to complete an operation cycle, it became possible to interact with the computer with a series of requests and responses expressed as specially formatted strings of text using a specialized vocabulary. Requests could be completed in seconds, no longer hours and days, and it made sense for the user to simply wait for the request to be completed before entering in the request. As opposed to queueing up a mult-stage program and waiting for all the stages to be completed, the user can change their mind about the structure of later stages in the program in response to feedback from earlier stages. This introduces the possibility for software to explore a set of possibilities with the guidance of the user and allows for a type of interactivity not possible in the 1950s. 

Although the earliest command-line systems borrowed typewriter-like teletypes (used for telegraph transmission) as the input and output mechanism, by the 1970s video display terminals were used with computers for providing text feedback on a virtual canvas of pixels that could be rapidly and reversibly modified (unlike teletype printers) and it became possible for a program to display an interface that could be called visual as opposed to textual \cite{unix2008}.

\section{Task Analysis}

Task analysis is a class of techniques used in HCI to guide the design of user interfaces. One of the central assumptions of user interface design and HCI is that different tasks require different interfaces. The corollary is that thinking carefully about the nature of the tasks that are meant to be accomplished by the interface will lead to better design decisions. Crystal and Ellington (2004) performed an in-depth comparative analysis of the dominant techniques and provide a good introduction to the motivations of task analysis:

\begin{quote}
Practitioners and researchers routinely advocate building user-centered systems which enable people to reach their goals, take account of natural human limitations, and generally are intuitive, efficient and pleasurable to use (Preece, Rogers and Sharp, 2002). Central to the design of such systems is a clear understanding of what users actually want to do: What are their tasks? What is the nature of those tasks? Many techniques have been proposed to help answer these questions. Task analysis techniques are particularly important because they enable rigorous, structured characterizations of user activity. They provide a framework for the investigation of existing practices to facilitate the design of complex systems.
Task analysis is especially valuable in the context of human-computer interaction (HCI). User interfaces must be specified at an extremely low level (e.g. in terms of particular interaction styles and widgets), while still mapping effectively to users’ high-level tasks. Computer interfaces are often highly inflexible (when compared to interacting with a physical environment or another person). This inflexibility magnifies the impact of interface design problems, making the close integration of task structure and interface support especially crucial. \cite{crystal2004}
\end{quote}

Broadly, task analysis consists of the observational and heuristic analysis of the physical, mental, and contextual requirements for performing a specific task. As such, even in its most rigorous and quantitative forms, task analysis typically involves methods like discourse analysis, contextual inquiry, and video analysis. 

The roots of scientific task analysis go back to 1911 when Frederick Taylor published \emph{The Principles of Scientific Management} \cite{crystal2004}. Taylor was interested in improving manufacturing productivity and incorporating understanding of human factors into work methods. Known commonly as Taylorism, he argued that managers should rigorously systematize the organization of workers based on empirical evidence. Of course, it is more accurate to refer to Taylor's discipline as something like job design; however, the relevant point here is that effort was being made to examine the efficacy of performing a task in one way as opposed to another. The psychological component of such job design was first examined by Harvard Business School between 1927 and 1932 at the Western Electric Hawthorne Plant. The studies essentially concluded that the psychology of individuals with the workplace contribute significantly to what workers produce and expect from their jobs.

It soon became commonplace for industrial engineers to incorporate analyses of production methods to improve interaction between humans and machines. As computers became a common machine that humans were interacting with in the workplace and the power and flexibility of computers as tools has expanded, human-computer interaction (HCI) is now a dedicated discipline. 

This increased flexibility has meant that computers are becoming entangled in new areas of human behavior like music. Multiple techniques have developed to deal with this greater scope and complexity required of task analysis and each technique focuses on different aspects and contributes different insights into the nature of a human task.

The relevant point regarding the use of HCI techniques like task analysis to analyse artistic systems is that HCI, and thus user interface and data visualization design, has borne the fingerprints of a discipline that was ultimately derived from the standpoint of increasing productivity and improving job performance. 

\section{Graphical Perception and Information Seeking}
\begin{comment}
The Structure of the Information Visualization Design Space, Section 2 
controlled vs. automatic processing
connection

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}
\subsection{Recognition vs. Recall}
\section{Modal Interfaces}

\section{Filtering}
\begin{comment}
The Structure of the Information Visualization Design Space, Section 5
dynamic queries technique 

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}
\section{Hierarchies and Taxonomies}
\begin{comment}
Magic number seven, George Miller
The Structure of the Information Visualization Design Space, Section 2
enclosure
\end{comment}
