\resetdatestamp

\chapter{User Interface and Data Visualization Design}

The bounds of the discipline of \emph{human-computer interaction} vary depending on who is asked. At present, people who practice the discipline seem to agree that human-computer interaction (HCI) involves "the design, implementation and evaluation of interactive systems in the context of the user's task and work" \cite{hci1998}. 

Within the broad domain of interactive systems, different subdisciplines within human-computer interaction (HCI) focus on different aspects of the systems. Designing a user interface for manipulating a Mapper network is an interesting task because the design problem is a composite of two interrelated subproblems. The first is visualizing the current state of the Mapper network in such a way as to allow a user to quickly reason about other possible states of the network. Solving this first problem effectively helps with the second problem, which is creating an interface that allows a user to determine what actions within the interface should be taken to move the network to a different, more desirable state. 

Conveniently there are two subdisciplines within HCI that task themselves with analyzing precisely these two problems: \emph{data visualization design} and \emph{user interface design}. Literature in these fields have much to say on the topic of how to proceed with the design of an interface and this chapter will focus on the findings that are most relevant to Vizmapper. To better understand the broader context of HCI, this chapter begins with a history of user interfaces in relation to the parallel history of general purpose computers.

\section{Short History of User Interfaces}

The term \emph{user interface} is a byproduct of historical developments in computing and makes best sense in the context of modern computing culture. The use of \emph{user interface} as a distinct concept was not needed when the \emph{user} was certain to be a professional engineer or programmer involved in the creation of the program and/or the machine that was to run the program; at the very least, they were comfortable interacting with the computer using the same means as the original programmer and did not require an explicitly designed interface to augment the usability of the system \cite{continuity1990}. Since \emph{user} is such a vague term, \emph{computer interface} is often used to refer to the part of the system that is meant by the term \emph{user interface}. This part of the system is the computer's interface to the world - whether the \emph{user} is assumed to be a programmer, a musician, another machine, the larger environment, etc. 

The concerns of user interface designers have changed considerably since people first started interacting with programmable digital computers for processing, storing, and retrieving information. Understanding the context of and nature of the interdependent effect that fundamental developments in computing and their accompanying user interfaces have on each other helps one appreciate the impact that a seemingly frivolous thing like user interface can have on the development of the basic functionality of the computer - for example, the function  of using a computer for creating mappings between a distributed network of devices.  

\subsection{Punch cards}

The oldest computer interfaces largely depend on punch cards and paper tape as control mechanisms and paper printers for output and program feedback. On machines used during the 1950s and 1960s, in order to input a program and a dataset into a computer, first one prepares a deck of punched cards with a typewriter-like machine, then one feeds the deck to the computer \cite{oshistory2011}. Some machines can also mount reels of magnetic tape that store oft-used or previously generated datasets or precompiled utility software. On these early machines, a particular program being run from a deck of punch cards is assumed to have control of all the available resources of the computer. There would be no other resident software running on the machine handling auxiliary tasks like on modern computers. Any hardware devices required by a particular program like punch card readers and line printers had to be handled completely by the user program contained in the deck of cards fed to the machine. 

\emph{Operating systems} development grew out of the growing complexity of computer systems involving many cooperating devices, which themselves mirrored growth of the complexity of the programs that were written for them. It makes little sense for a user of a machine to write basic operating software for interfacing with the same perhipheral devices as every other user of the computer everytime they want to run a program on such a machine. Since any user of a computer during the 1960s needed to enter a queue to reserve time to run their program on a machine they shared with their entire organization, any time wasted debugging low-level interactions with input and output devices is a major setback \cite{operatingsystems2010}. Consequently, machines were developed that included libraries of code to take care of low-level control and provide easier access to input and output devices as always resident services. This collection of software that is permenantly resident on a machine became known as a \emph{batch monitor} \cite{os2000}. A user's program could link to these preloaded libraries without including the operating logic explicitly within their own program code. This shift is often cited as the genesis of the modern operating system.

In addition to providing access to input/output devices, the monitor provides services to perform error checking on user submitted programs and for generating useful feedback to the user concerning the progress of execution of a user program. The idea of generating "useful" feedback, and what that might mean, can be understood as the first instance of an explicitly designed user interface and the birth of user interface design \cite{unix2008}.

\subsection{Command-line}

Command-line interfaces are the next step in the evolution of computer interfaces and the link between batch systems of the 1950s and what would be recognized as a \emph{graphical user interface} (GUI) today. As processors developed further and resulted in the reduction of the amount of time needed to execute a basic operation on data, it became possible to interact with the computer more granularly with a series of requests, execute programs pseudo-instantaneously, and receive responses expressed as specially formatted strings of text using a specialized vocabulary. Requests could be completed in seconds, no longer hours and days, and it made sense for the user to simply wait for the request to be completed before entering in the next request. This is as opposed to sequencing a stack of commands in the form of a batch request and waiting for all the commands to be completed or for one of the command to fail. Instead, the user can change their mind about the structure of commands in the composite program in response to feedback from earlier commands. This introduces the possibility for software to explore a set of possibilities with the guidance of the user and allows for a type of interactivity not possible with the batch systems of the 1950s. 

Although the earliest command-line systems borrow typewriter-like teletypes (as used for telegraph transmission) as the input and output mechanisms, by the 1970s video display terminals are used with computers for providing text feedback on a virtual canvas of pixels that can be rapidly and reversibly modified (unlike teletype printers) and a program can display an interface that could be called visual as well as just textual \cite{unix2008}. This allows programmers to create the first computer games and text editors that rely on this capability of video display terminals.

\subsection{Graphical}

Further reduction of the amount of time a processor needed to execute individual operations results in the ability for the computer to communicate with multiple input/output devices in realtime. Typical devices that a modern computer program expects to have access to through the operating system include a color monitor wherein each pixel in the monitor had a separate referenceable address, a graphics card to help with processing of 2d/3d graphics operations, a mouse, a keyboard, and a sound card connected to audio speakers.

Much of the common grammar of all the popular graphical user interfaces in use today are derivatives of two particular projects. The first is called NLS/Augment (NLS stands for oN-Line System) and was designed by Douglas Engelbart and his team at the Stanford Research Institute. During a famous, public demonstration of the system in 1968 (often affectionately referred to as "The Mother of All Demos"), Engelbart proceeded to demonstrate the use of a computer mouse, a graphical display with multiple windows, and hyperlinks among many other notable advancements in human-computer interaction. 

The second groundbreaking project, the Xerox Alto, came from the Xerox Palo Alto Research Center (PARC) in 1973. It is perhaps the first computer designed from inception to be dedicated to the use of a single person, hence the introduciton of the term \emph{personal computer}. Although the monitor displays only black and white pixels, the graphical user interface of the operating system contains buttons, windows, scrollbars, sliders, and many of the logical GUI components that are standard components of any program with a GUI. It is followed at PARC by the Xerox Star in 1981, which takes GUIs a step further towards their current incarnations and introduces the ability to share resources across a local area network \cite{xeroxstar1989}.

It is primarily the ideas that these two projects consolidate and introduce to the wider world that eventually becomes the impetus for the recognition of HCI and, of more precise relevance to this paper, user interface design as important areas of study of significant relevance to the broader computer science community. 

\subsection{Five Foci of Interface Development}

It is clear from history that, in some sense, computing machines have always had user interfaces. What changes is the the level of attention that any particular layer in the computing interface receives during various periods of history. Grudin \cite{continuity1990} introduces a helpful framework for understanding this change that takes place during the second half of the 20th century as movement through five different foci of interface design. 

\begin{enumerate}
\item Initially, during and before the days of punch cards, most users of computers are electrical engineers primarily concerned with working directly with the hardware (flipping switches, replacing vacuum tubes, wiring ports and circuits). Conceptually, the computer interface is located at the hardware itself. 

\item Afterwards, the primitive operating systems and batch monitors place the majority of focus on the task of programming and the environment in which commands are executed and requests are made and begins shifting focus away from the hardware. The development of ever higher-level languages and environments eventually replaces the need to be familiar with hardware particulars. At this point, the primary interface in these systems is at the level of the software code and programming. 

\item As machines begin to perform their operations more quickly, systems become interactive and users are not expected to be able to interact with the computer through computer code, the interface grows into the canonical monitor, keyboard, and mouse of the 1990s and 2000s. It makes sense for designers of computer systems to become more concerned with issues of perception and motor control. 

\item In recent years it has become practical to interact with the computer in a more conversational/realtime manner and system designers focus on the entire process of a user interacting with the system over an extended period of time, from initial exposure to practiced expert interaction. The focus of the interface designer becomes less trained on issues of ergonomics and visual perception and more trained on deeper cognitive issues like learning and problem solving. The interface now encompasses the proclivities of the mind. 

\item Impressively, Grudin predicts the advent of social networking in what he labels \emph{groupware}, the fifth focus of interface development. When a single system serves a large group of interacting people (setting this scenario apart from the earliest batch systems where different users rarely interacted) as opposed to an individual, the user interface becomes entangled with the dynamics of interaction between the members of the group.
\end{enumerate}

Ultimately, Grudin cites these observations within the context of the framework of five foci to support the assertion that the history of the computer is one of the computer extending its interface with the world outward from its hardware implementation and deep into the intanglible aspects of human behavior and a broader understanding of how we accomplish tasks in everyday life \cite{continuity1990}.

\section{Task Analysis}

Task analysis is a class of techniques used in HCI to guide the design of user interfaces. One of the central assumptions of user interface design and HCI is that different tasks require different interfaces. This is mirrored in the history of user interfaces. As the users and tasks performed with the computer changes, so does the interface. A corollary of this premise is that thinking carefully about the nature of the tasks that are meant to be accomplished through the interface results in better design decisions. Crystal and Ellington performed an in-depth comparative analysis of the dominant techniques and provide a good introduction to the motivations of task analysis:

\begin{quote}
"Practitioners and researchers routinely advocate building user-centered systems which enable people to reach their goals, take account of natural human limitations, and generally are intuitive, efficient and pleasurable to use (Preece, Rogers and Sharp, 2002). Central to the design of such systems is a clear understanding of what users actually want to do: What are their tasks? What is the nature of those tasks? Many techniques have been proposed to help answer these questions. Task analysis techniques are particularly important because they enable rigorous, structured characterizations of user activity. They provide a framework for the investigation of existing practices to facilitate the design of complex systems.

Task analysis is especially valuable in the context of human-computer interaction (HCI). User interfaces must be specified at an extremely low level (e.g. in terms of particular interaction styles and widgets), while still mapping effectively to users high-level tasks. Computer interfaces are often highly inflexible (when compared to interacting with a physical environment or another person). This inflexibility magnifies the impact of interface design problems, making the close integration of task structure and interface support especially crucial." \cite{crystal2004}
\end{quote}

Broadly, task analysis consists of the observational and heuristic analysis of the physical, mental, and contextual requirements for performing a specific task. As such, even in its most rigorous and quantitative forms, task analysis typically involves less quantitative methods like discourse analysis, contextual inquiry, and video analysis. 

The roots of scientific task analysis go back to 1911 when Frederick Taylor published \emph{The Principles of Scientific Management} \cite{crystal2004}. Taylor was interested in improving manufacturing productivity and incorporating understanding of human factors into work methods. Known commonly as Taylorism, he argued that managers should rigorously systematize the organization of workers based on empirical evidence. Of course, it is more accurate to refer to Taylor's discipline as something like job design; however, the relevant point here is that effort was being made to examine the relative efficacy of performing a task using different methods. The psychological component of such job design was first examined by Harvard Business School between 1927 and 1932 at the Western Electric Hawthorne Plant. The studies essentially concluded that the psychology of individuals with the workplace contribute significantly to what workers produce and expect from their jobs.

It soon became commonplace for industrial engineers to incorporate analyses of production methods to improve interaction between humans and machines as the efficiency of machines became as important as the efficiency of humans in production methods. As computers become a typical machine that humans interact with in the workplace and the power and flexibility of computers as tools expands, human-computer interaction (HCI) evolves into its own discipline and broadens its scope. 

This increased flexibility means that computers become entangled in new areas of human behavior like music. Techniques are developed to deal with this greater scope and complexity required of task analysis and each technique focuses on different aspects and contributes different insights into the nature of a human task.

An important point that should be extracted from this history, regarding the use of HCI techniques like task analysis to analyse artistic systems, is that HCI and thus user interface and data visualization design, bear the fingerprints of a discipline that ultimately derives from the standpoint of increasing productivity and improving job performance. Therefore, the principles advanced by HCI should always be evaluated (and potentially ignored) in the broader context of particular scenarios \cite{orio2002}. Despite this reality, task analysis is the primary means of analyzing the mapping task in Chapter 4 and the mindset of this analytical technique is the basis of the process used to arrive at the final design of Vizmapper for this thesis.

\section{Graphical Perception and Information Visualization}
\label{sec:Graphical Perception}

\begin{quote}
"Graphics is the visual means of resolving logical problems."
\end{quote}

This idea from Bertin \cite{semiology1983}, who is one of the first to provide a theoretical foundation to data visualization, summarizes the hope for a dedicated interface for configuring a Mapper network. It is in this context that \emph{data visualization} or \emph{information visualization} is understood to be "the computer-assisted use of visual processing to gain understanding" by Card \cite{card1997}. 
The task of mapping is a logical problem, as well as an artistic one. It is a logical problem in the sense that one cannot make connections haphazardly between any pair of input and output signals and expect the network mapping that is produced to be interesting as a DMI or meet the goals of the design team. One must still infer, through some form of reasoning, the suitability of a particular signal connection in the context of the particular devices on the network, the nature of the signals that the devices produce, and the broader artistic intentions of the design team. 

It could be that one output signal generates floating-point decimal values and one input signal accepts only integer values. Or if a specific output signal tends to generate a static signal regardless of the gestures or environmental dynamics sensed by the control mechanism of the MSN, it would make for a very dull and non-dynamic performance to connect this output signal to the input signal controlling the pitch of an audio synthesizer. Of course, as previously stated, one does not typically make use of metrics like productivity or performance in an artistic context, so the logical problem is different. But even an artistic project has goals and intentions, though they are considerably harder to define in words. Visualizing a Mapper network effectively within a user interface will likely help a team of people (as long as there is agreement about the artistic and other intentions of the scenario that the MSN is to be used in), resolve these logical problems involving network topology and signal transformation more effectively. 

Graphics are thought to have at least two distinct uses. The first is communicating a set of information. The second is acting as a medium for graphical processing, defined as using the perception and manipulation of graphical objects to understand the information \cite{card1997}. Any graphical interface that is monitoring a Mapper network will likely incorporate both uses of graphics. The interface needs to effectively communicate the current state of the network, including the namespaces and properties of all registered devices and signals and the set of signal connections and transformations between outputs and inputs. Also, the interface must allow the user to manipulate the graphics to connect and disconnect signals and apply functional transformations to the signal data.

It is useful to categorize all possible data into three types, as distinguished by their function \cite{semiology1983}\cite{card1997}:
\begin{description}
\item \emph{Nominal} - data values that are understood as either = or not = to each other - examples are the set of religions, colors, and professions
\item \emph{Ordinal} - data values that can be understood using a greater-than or less-than relation in some way - an example is the set of the days of the week
\item \emph{Quantitative} - data values that can be manipulated with arithmetic - an example is the population of a city 
\end{description}

Note that each successive functional type is a special case of the previous types. All quantitative data is necessarily ordinal data and nominal data. All ordinal data is necessarily nominal data. Conversely, only some nominal data is ordinal and only some ordinal data is quantitative.

\begin{table}
    \begin{center}
    \begin{tabular}{ | l | l | l | }
    \hline
    Nominal & Ordinal & Quantitative \\ \hline
    Position & Position & Position \\
    Color Hue & Density & Length \\
    Texture & Color Saturation & Angle \\
    Connection & Color Hue & Slope \\
    Containment & Texture & Area \\
    Density & Connection & Volume \\
    Color Saturation & Containment & Density \\
    Shape & Length & Color Saturation \\
    Length & Angle & Color Hue \\
    Angle & Slope & \cellcolor{black}\textcolor{white}{Texture} \\
    Slope & Area & \cellcolor{black}\textcolor{white}{Connection} \\
    Area & Volume & \cellcolor{black}\textcolor{white}{Containment} \\
    Volume & \cellcolor{black}\textcolor{white}{Shape} & \cellcolor{black}\textcolor{white}{Shape}\\
    \hline
    \end{tabular}
    \end{center}
    \caption{Ranking of perceptual tasks for each fundemental data type (N.B. black background indicates non-applicability of the task for that data type) \cite{jock1986}}
    \label{tab:perceptual}
\end{table}

Depending on the functional type of the data being visualized, certain forms of visual differentiation are more effective than others. Card et al. \cite{card1997} use the distinction between \emph{automatic processing} and \emph{controlled processing} capacities in human visual processing to inform an analysis of visualization techniques. Automatic processing works on visual properties like position and color and is highly parallelized, but lacks the complexity of highly structured visual information. Controlled processing notably works on text and can deal with more complex information, but is not very parallelized because it requires conscious attention \cite{controlauto1977}. This is why it is easier to assess a large amount of data displayed as graphics that take advantage of automatic processing than words and numbers that require controlled processing.

It is common in the literature to decompose any information graphic into \emph{marks} (points, lines, areas, surfaces, or volumes), the \emph{automatically processed graphical properties} of those marks (position, color, size, shape, etc...), and the \emph{controlled processing graphical properties} of those marks (if the mark has external semantic meaning as language or numbers). 

A well-cited study by Cleveland and McGill \cite{cleveland1984} forms the basis of a theory about the relative accuracy with which people infer quantitative information among the base automatically processed perceptual tasks that can be employed in a graphical presentation of data. This theory is expanded upon by Mackinlay \cite{jock1986} to form the ranking displayed in Table \ref{tab:perceptual}. This theory is useful for deciding how to map the available perceived graphical properties to the variable components of a data set because it allows one to rank the effectiveness of possible graphical languages. Mackinlay communicates the importance of such a ranking through the common sense \emph{Principle of Importance Ordering}:

\begin{quote}
"Encode more important information more effectively." \cite{jock1986}
\end{quote}

\begin{comment}
The Structure of the Information Visualization Design Space, Section 2 
controlled vs. automatic processing
connection

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}

Of course, this presumes a method for analyzing the different components in a data set and characterizing the relative importance of the different variables present in a data set.

The most extensive theoretical framework for the display of graphical information is presented in a book called the \emph{Semiology of Graphics} by Bertin \cite{semiology1983}. He describes a three stage process for analyzing the data in preperation for designing a visualization.

\begin{enumerate}
\item The first stage is determining the number of \emph{components} or \emph{variables} present in the data. A component is defined as a concept in the data that varies across a number of \emph{elements} particular to the component. For example, the component of "output signals present on a Mapper network" varies across the set of output signals labeled by their declared network name. Similarly one could define another component encapsulating the variation in the available input signals. 

\item The second stage is determining to \emph{length} of each component in the data set. The length is defined as the number of elements which are uniquely identifiable in the component. If the component is "the states in the United States", the length of the component is 50. Bertin's concept of \emph{length} is very similar to the concept of \emph{cardinality} explored in Chapter 2. The cardinality of a component is important for choosing the perceptual graphical property to map to a component in a data set because a high cardinality component requires a mapping to a perceptual task that is able to be finely differentiated whereas a lower cardinality component can be mapped to a task that people tend to differentiate more coarsely. Since each graphical property of a particular mark can only be used to represent one component for clarity, it is important not to waste a high resolution perceptual task on a low cardinality component.

\item The third stage is determining the functional type of the component as previously defined (nominal, ordinal, or quantitative). Bertin calls this property of a component the \emph{level of organization}.
\end{enumerate}

This analysis can then be used in combination with Table \ref{tab:perceptual} to make sure the data of each component is transcribed with a visual variable possessing the same cardinality and level of organization and thus contributing to an efficient visualization.

This theoretical framework will be used in Chapter 4 to weigh possible visualization choices for Vizmapper.

\section{Recall and Recognition}

There are certain aspects of cognitive functionality that are well-studied and easily applied to interface design. These provide useful theoretical guides for designing efficient user interfaces. The remainder of this chapter outlines those hypotheses that are most relevant to the Vizmapper interface.

It is common to understand human information retrieval in terms of two types of retrieval, recall and recognition. In the recall process, information is reproduced from memory. In the recognition process, a piece of information induces the knowledge that the information is not new; it has been seen before and the information acts as a cue \cite{hci1998}. In this respect, recognition is a less complex cognitive activity. Recall can be assisted with cues that allow an individual to speed access to the information in their memory. One proven cue is the use of categories.

Modern understandings of recognition and recall attribute the relative effectiveness of the two processes to the way in which perception and memory are interconnected \cite{mindinmind2010}.

\begin{quote}
"Activating a memory consists of reactivating the same pattern of neural activity that occured when the memory was formed. Somehow the brain distinguishes initial activations of neural patterns from reactivations - perhaps by measuring the relative ease with which the pattern was reactivated. New perceptions very similar to the original ones reactivate the same patterns of neurons, resulting in \emph{recognition} if the reactivated perception reaches awareness. In the absence of a similar perception, stimulation from activity in other parts of the brain can also reactivate a pattern of neural activity, which if it reaches awareness results in \emph{recall}." \cite{mindinmind2010}
\end{quote}

HCI practioners have long known about this interesting byproduct of the evolution of the brain as the creators of the Xerox Star point out in explaining their design decisions for the system.

\begin{quote}
"Traditional computer systems require users to remember and type a great deal just to control the system. This impedes learning and retention, especially by casual users. Star's designers favored an approach emphasizing recognition over recall, seeing and pointing over remembering and typing." \cite{xeroxstar1989}
\end{quote}

This basic understanding of recall and recognition provides an easily applicable rule for building an effective interface.

\section{Hierarchies and Taxonomies}

\begin{comment}
Papers:
Magic number seven, George Miller
recoding pg. 93
increasing bits per chunk
The Structure of the Information Visualization Design Space, Section 2
enclosure
Coding Recoding Hierarchical Information
Acquisiton and forgetting of hierarchically organized information
\end{comment}

Hierarchies and taxonomies (classification schemes arranged hierarchically and used often in science) are widely used to reduce the complexity of a data set (like the set of all the animals in world is organized by kingdom, phylum, class, etc...) by dividing up the data set into smaller subsets and relating the subsets to the larger superset. It is believed that this general process plays a central role in recall, recognition, and problem solving \cite{seven1956}\cite{graphicalhierarchy1972}\cite{hierarchical1971}. 

The basis of this theory stems from a famous paper by George A. Miller called \emph{The Magical Number Seven} \cite{seven1956}. Central to Miller's two central hypotheses is the common concept of the \emph{bit}. Briefly, one bit of information is defined as the amount of information that is required to make a decision between two equally likely alternatives \cite{seven1956}. It is precisely the amount of information that is required to know whether a flipped coin is heads or tails. Two bits is the amount of information needed to decide between four equally likely alternatives. Three bits is the amount of information needed to decide between 8 equally likely alternatives and so on...

The first hypothesis is that a person's ability to distinguish between elements of a set, regardless of what sense is perceiving the elements, is roughly limited to between 2.3 and 2.8 bits (this is not \emph{exactly} what Miller says), which corresponds to 7 plus or minus two elements. This is referred to as the \emph{span of absolute judgement}. Note well, that this is only true of elements that vary along one perceived dimension. For instance, human faces are perceived among multiple visual property dimensions. Otherwise, we would never be able to distinguish between the faces of more than 10 people! Also, there are well-known exceptions to this rule. A musical example is the ability of a person with \emph{absolute pitch} to accurately distinguish between around 60 different pitches \cite{seven1956}. The exact number of bits understood to be average span of absolute judgement has changed as our understanding of the brain has improved since 1956, but what has not changed is that the number is lower than one might expect. 

The second related hypothesis has to do with the \emph{span of immediate memory}. Immediate memory is the abstract model of the temporary memory store that one uses during conscious reasoning. In this case, the relevant parameter is no longer a bit, but a \emph{chunk}. The number of chunks that humans can hold in immediate memory and reason about is also about 7. A chunk can represent a similarly low magic number of bits (two to three) in immediate memory. However, a chunk can also represent a similar number of chunks instead of bits, which allows one to reason about a large number of bits of information as long as they are hierarchically organized such that lower level chunks are represented by higher level chunks.

\begin{quote}
"In the jargon of communication theory, this process would be called \emph{recoding}. The input is given in a code that contains many chunks with few bits per chunk. The operator recodes the input into another code that contains fewer chunks with more bits per chunk. There are many ways to do this recoding, but probably the simplest is to group the input events, apply a new name to the group, and then remember the new name rather than the original input events." \cite{seven1956}
\end{quote}

Given this, it is not altogether surprising that the following is also known. For a given set of unknown associative connections between a set of elements that presenting the connections as a graphical hierarchy aids learning the structure of connections \emph{much} more than a list of connections \cite{graphicalhierarchy1972}. This fact is immediately applicable for visualizing a Mapper network.

In summary, if an interface expects a user to make decisions involving a set of high cardinality than there must be a form of hierarchical organization of the elements of the set. Otherwise, the user will not be able to proceed very effectively or accurately.

\section{Filtering and Information Seeking}

\begin{comment}
The Structure of the Information Visualization Design Space, Section 5
dynamic queries technique 

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}

When dealing with a data set with a high cardinality for one component or another, filtering becomes a very attractive feature for a user interface to have. This is especially true when the goal of a user interface or data visualization is not only to improve the ability for a user to extrapolate high level integrative knowledge about the set of data, but to focus on and select specfic data for manipulation as required by the Vizmapper interface. This focus is related to data visualization, but is referred to as \emph{visual information seeking} (VIS) to distinguish it from data visualization. 

Filtering, like hiearchical organization, provides a mechanism for reducing the perceived complexity of a data set. Unlike hiearchical organization, which preserves the overall cardinality of the data set, filtering temporarily restricts the visible set to a subset within the complete set that meet the parameters of the filter. Filters can be implemented graphically by using sliders, drop down menus, and other common graphical widgets or use textual queries. Hierarchical organization can itself be used as a filtering mechanism by acting as predefined set of salient queries (for example, to restrict the set of all animals to mammals from a typical hiearchical biological classification).

Most of this understanding of filters in the context of VIS comes from a paper by Ahlberg and Schneiderman \cite{seeking1994}. The relevance of filters to the problem of mapping in a large MSN is best summarized as follows:

\begin{quote}
"The key to these principles is understanding the enormous capacity for human visual information processing. By presenting information visually and allowing dynamic user control through direct manipulation principles, it is possible to traverse large information spaces and facilitate comprehension with reduced anxiety." \cite{seeking1994}
\end{quote}

The principle of \emph{tight coupling} in a user interface is of particular interest when including filtering capabilities in an interface because it makes clear the distinction between filtering and searching. Tight coupling applies to many aspects of a user interface and broadly refers to maintaining tightly coupled consistency between the state of a data visualization and any user actions that are supposed to change the state of the system. If it is possible for a user to break this consistency between the visual state of the system and the actual state of the system the user will likely be confused. 

Typically when searching a database the system state begins by displaying an empty set of data because no query has been made. Once a query is executed than the interface displays a subset of data (in graphical or textual form) that correspond to the elements of the entire data set that match the search query. Conversely, when filtering a data set the initial state of the system with an empty query is to display the entire set of available data and to reduce the amount of information on the screen as the query becomes more specific. The difference is admittedly subtle. However, when a user is introduced to a large data set for the first time, the filtering convention is much less confusing because it is much more disorienting to be presented with a empty set of data than it is to be presented with too much data \cite{seeking1994}. It is more difficult for a user to determine what the first action to take should be in the former case.

The purpose of introducing these aspects of cognition and effective design that others have discovered is not to provide a set of \emph{rules} to govern the decisions that are made in the Vizmapper design. Many of these connections between interfaces and cognition are not rigorously provable in the sense that the principles of physics or electrical engineering are arguably provable. The purpose of the introduction of this thesis, and specifically the initial quotation, is to make this clear from the outset. 

However, this is the minimum due diligence that ought to be applied when making a good faith attempt to \emph{improve} how someone accomplishes a task. The history and research reviewed in this chapter provide a solid theoretical foundation for tackling the broad problem of designing a user interface and the specific problem of visualizing and manipulating a large data set through a graphical user interface. 
