\resetdatestamp

\chapter{User Interface and Data Visualization Design}

\section{Relevant History of Human-Computer Interfaces}

The concerns of user interface designers have changed considerably since people first started interacting with programmable digital computers for processing, storing, and retrieving information. 

\subsection{Punch cards}

The first interfaces often depended on punch cards and paper tape as control mechanisms and line printers for output and program feedback. On machines used during the 1950s and 1960s, in order to input a program and a dataset into a computer, first one prepares a deck of punched cards using a typewriter-like machine, then one feeds the deck to the computer \cite{oshistory2011}. Optionally on some machines, one can mount reels of magnetic tape that store oft-used or previously generated datasets or compiled software. On these early machines, a particular program being run from a deck of punch cards would occupy the resources of the entire computer. Any hardware devices required by a particular program like punch card readers and line printers had to be handled completely by the program. 

\emph{Operating systems} development grew out of the growing complexity of computer systems involving many cooperating devices and the mirrored growth of the complexity of the programs that were written for them. It makes little sense for a user of a machine to write basic operating software for interfacing with standardized perhipheral devices everytime they want to run a program on such a machine. Especially, since any user of a computer during the 1960s likely needed to enter a queue to reserve time to run their program on a single shared machine and any time wasted debugging low-level interactions with input and output devices was surely frusterating. Predictably, machines begain appearing with libraries of code that took care of low-level control and provided easier access to input and output devices as always resident services. This collection of software that is permenantly resident on a machine became known as a \emph{batch monitor} \cite{os2000}. A user's program could link to these preloaded libraries without including the operating logic explicitly within their own program code. This shift is often cited as the genesis of the modern operating system.

In addition to providing access to input/output devices, the monitor often provided services to perform error checking on user submitted programs and generating useful feedback to the user concerning the progress of execution of a user program. The idea of generating "useful" feedback, and what that might mean, can be understood as the first instance of an explicitly designed user interface \cite{unix2008}.

\subsection{Command-line}

Command-line interfaces are the next step in the evolution of computer interfaces and the link between batch systems of the 1950s and what would be recognized as a \emph{graphical user interface} (GUI) today. With continual, steady reduction of the amount of time needed to complete a computation cycle, it became possible to interact with the computer with a series of requests and responses expressed as specially formatted strings of text using a specialized vocabulary. Requests could be completed in seconds, no longer hours and days, and it made sense for the user to simply wait for the request to be completed before entering in the request. As opposed to queueing up a mult-stage program and waiting for all the stages to be completed, the user can change their mind about the structure of later stages in the program in response to feedback from earlier stages. This introduces the possibility for software to explore a set of possibilities with the guidance of the user and allows for a type of interactivity not possible in the 1950s. 

Although the earliest command-line systems borrowed typewriter-like teletypes (used for telegraph transmission) as the input and output mechanism, by the 1970s video display terminals were used with computers for providing text feedback on a virtual canvas of pixels that could be rapidly and reversibly modified (unlike teletype printers) and it became possible for a program to display an interface that could be called visual as well as textual \cite{unix2008}. This allowed programmers to create the first computer games and text editors that relied on this capability of video display terminals.

\subsection{Graphical}

Further reduction of the amount of time needed to execute individual operations within a program resulted in the ability for the computer to communicate with multiple input/output devices in realtime. Typical devices that a modern computer program expects to have access to through the operating system include a color monitor wherein each pixel in the monitor had a separate referenceable address, a graphics card to help with processing of 2d/3d graphics operations, a mouse, a keyboard, and a sound card connected to audio speakers.

Much of the common grammar of all the popular graphical user interfaces in use today were developed by two particular projects. The first is called NLS/Augment (NLS stands for oN-Line System) and was designed by Douglas Engelbart and his team at the Stanford Research Institute. During a famous, public demonstration of the system in 1968 (affectionately, often referred to as "The Mother of All Demos"), Engelbart proceeded to demonstrate the use of a computer mouse, a graphical display with multiple windows, and hyperlinks among many other notable advancements in human-computer interaction. 

The second groundbreaking project, the Xerox Alto, came from the Xerox Palo Alto Research Center (PARC) in 1973. It is perhaps the first computer designed from inception to be dedicated to the use of a single person. Although the monitor displayed only black and white pixels, the graphical user interface of the operating system contained buttons, windows, scrollbars, sliders, and many of the logical GUI components that are standard components of any program with a GUI.

It is primarily the ideas that these two projects consolidated and introduced to the wider world that eventually became the impetus for the recognition of \emph{Human-Computer Interaction} and, of more precise relevance to this paper, \emph{User Interface Design} as important areas of study of significant relevance to the broader computer science community. 

\section{Task Analysis}

Task analysis is a class of techniques used in HCI to guide the design of user interfaces. One of the central assumptions of user interface design and HCI is that different tasks require different interfaces. The corollary is that thinking carefully about the nature of the tasks that are meant to be accomplished by the interface will lead to better design decisions. Crystal and Ellington (2004) performed an in-depth comparative analysis of the dominant techniques and provide a good introduction to the motivations of task analysis:

\begin{quote}
Practitioners and researchers routinely advocate building user-centered systems which enable people to reach their goals, take account of natural human limitations, and generally are intuitive, efficient and pleasurable to use (Preece, Rogers and Sharp, 2002). Central to the design of such systems is a clear understanding of what users actually want to do: What are their tasks? What is the nature of those tasks? Many techniques have been proposed to help answer these questions. Task analysis techniques are particularly important because they enable rigorous, structured characterizations of user activity. They provide a framework for the investigation of existing practices to facilitate the design of complex systems.
Task analysis is especially valuable in the context of human-computer interaction (HCI). User interfaces must be specified at an extremely low level (e.g. in terms of particular interaction styles and widgets), while still mapping effectively to users’ high-level tasks. Computer interfaces are often highly inflexible (when compared to interacting with a physical environment or another person). This inflexibility magnifies the impact of interface design problems, making the close integration of task structure and interface support especially crucial. \cite{crystal2004}
\end{quote}

Broadly, task analysis consists of the observational and heuristic analysis of the physical, mental, and contextual requirements for performing a specific task. As such, even in its most rigorous and quantitative forms, task analysis typically involves methods like discourse analysis, contextual inquiry, and video analysis. 

The roots of scientific task analysis go back to 1911 when Frederick Taylor published \emph{The Principles of Scientific Management} \cite{crystal2004}. Taylor was interested in improving manufacturing productivity and incorporating understanding of human factors into work methods. Known commonly as Taylorism, he argued that managers should rigorously systematize the organization of workers based on empirical evidence. Of course, it is more accurate to refer to Taylor's discipline as something like job design; however, the relevant point here is that effort was being made to examine the efficacy of performing a task in one way as opposed to another. The psychological component of such job design was first examined by Harvard Business School between 1927 and 1932 at the Western Electric Hawthorne Plant. The studies essentially concluded that the psychology of individuals with the workplace contribute significantly to what workers produce and expect from their jobs.

It soon became commonplace for industrial engineers to incorporate analyses of production methods to improve interaction between humans and machines. As computers became a common machine that humans were interacting with in the workplace and the power and flexibility of computers as tools has expanded, human-computer interaction (HCI) is now a dedicated discipline. 

This increased flexibility has meant that computers are becoming entangled in new areas of human behavior like music. Multiple techniques have developed to deal with this greater scope and complexity required of task analysis and each technique focuses on different aspects and contributes different insights into the nature of a human task.

The relevant point regarding the use of HCI techniques like task analysis to analyse artistic systems is that HCI, and thus user interface and data visualization design, has borne the fingerprints of a discipline that was ultimately derived from the standpoint of increasing productivity and improving job performance. 

\section{Graphical Perception and Information Seeking}

\begin{quote}
Graphics is the visual means of resolving logical problems. \cite{bertin1981}
\end{quote}

This idea from Bertin, who conducted one of the first attempts to provide a theoretical foundation to information visualization, summarizes the hope for an alternative interface for configuring a Libmapper network. 

The task of mapping is a logical problem, as well as an artistic one. It is a logical problem in the sense that one cannot make connections haphazardly between any pair of input and output signals and expect the network mapping that is produced to be interesting as a DMI. One must still infer through some form of reasoning the suitability of a particular connection in the context of the particular devices on the network, the nature of the signals that the devices produce, and the broader artistic intentions of the design team. 

It could be that one output signal generates floating-point decimal values and one input signal accepts only integer values. Or if a specific output signal tends to generate an essentially static signal regardless of the gestures performed with the MSN, it would make for a very dull and non-dynamic performance to connect this signal to the pitch input signal of a audio synthesizer. Of course, as previously stated one does not typically make use of metrics like productivity or performance in an artistic context, so the logical problem is different. But even an artistic project has goals and intentions, though they are considerably harder to define in words. Visualizing the Libmapper network effectively within a user interface will likely help a team of people (as long as there is agreement about the artistic and other intentions of the scenario that the MSN is to be used in), resolve these logical problems involving network topology and signal transformation more effectively. 

According to Bertin, graphics have at least two distinct uses. The first is as a means of communicating some information. The second is as a medium for graphical processing, defined as using the manipulation and perception of graphical objects to understand the information \cite{card1997}. Any graphical interface that is monitoring a Libmapper network will likely incorporate both uses of graphics. The current state of the network, including the namespaces and properties of all registered devices and signals and all signal connections and transformations, needs to be able to be gleaned from the interface. Also, the interface must allow the user to manipulate the graphics in such a way as to facilitate the connection and disconnection of signals with or without functional transformations applied to the signals.

\begin{comment}
The Structure of the Information Visualization Design Space, Section 2 
controlled vs. automatic processing
connection

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}
\section{Recognition vs. Recall}
\section{Modal Interfaces}

\section{Filtering}
\begin{comment}
The Structure of the Information Visualization Design Space, Section 5
dynamic queries technique 

Visual Information Seeking: Tight Coupling of Dynamic Query Filters with Starfield Displays
\end{comment}
\section{Hierarchies and Taxonomies}
\begin{comment}
Magic number seven, George Miller
The Structure of the Information Visualization Design Space, Section 2
enclosure
\end{comment}
