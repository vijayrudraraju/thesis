\resetdatestamp

\chapter{Vizmapper}

With the benefit of the research and context that is presented in chapters 2 and 3, it is now possible to embark on an informed analysis of the mapping task for an MSN and to make informed decisions about the implementation of the system.

The graphical user interface to Libmapper that is the result of these design choices is called Vizmapper.

The task of mapping is understood from chapter 2 to be creating a set of associations and functional transformations between a set of signals being output by a set of devices (usually with sensors) and a set of inputs made available by various devices (usually with audio synthesis modules)  capable of receiving signals.

The context in which the task of mapping is performed is understood to be one to many programmers, engineers, composers, and/or musicians interested in experimenting with interactive musical systems for use in a creative (as opposed to business productivity or analysis) context.

\section{Task Analysis of DMI Mapping}
\begin{comment}
Task analysis and human-computer interaction: approaches, techniques, and levels of analysis - Abe Crystal, Beth Ellington
\end{comment}

The section on task analysis in chapter 3 concluded that as a technique it is best-suited to understanding how to design interfaces that maximize productivity as opposed to channeling creative expression. This may or may not present a problem, depending on whether we choose the characterize the use of computer in the context of accomplishing the task of mapping as an act of expression or an act of productivity. Atau Tanaka offers a line of thinking that applies to tools and instruments, but may be of use in attempting to resolve this problem \cite{tanaka2000}.

\begin{quote}
"A tool can be improved to be more efficient, can take on new features to help in realizing its task, and can even take on other, new tasks not part of the original design specification. In the ideal case, a tool expands the limits of what it can do. It should be easy to use, and be accessible to [sic] wide range of naive users. Limitations or defaults are seen as aspects that can be improved upon.

A musical instrument's raison-d'etre, on the other hand, is not at all utilitarian. It is not meant to carry out a single defined task as a tool is. Instead, a musical instrument often changes context, withstanding changes of musical style played on it while maintaining its identity. A tool gets better as it attains perfection in realizing its tasks. The evolution of an instrument is less driven by practical concerns, and is motivated instead by the quality of sound the instrument produces. In this regard, it is not so necessary for an instrument to be perfect as much as it is important for it to display distinguishing characteristics, or "personality". What might be considered imperfections or limitations from the perspective of tool design often contribute to a "personality" of a musical instrument.

Computers are generalist machines with which tools are programmed. By itself, a computer is a tabula rasa, full of potential, but without specific inherent orientation. Software applications endow the computer with specific capabilities. It is with such a machine that we seek to create instruments with which we can establish a profound musical rapport.

The input device is the gateway through which the user accesses the computer software's functionality. As a generalist device, generalized input devices like the keyboard or mouse allow the manipulation of a variety of different software tools. Music software can be written to give musically specific capabilities to the computer. Input devices can be built to exploit the specific capabilities of this software. On this general platform, then, we begin to build a specialized system, each component becoming part of the total instrument description." 
\end{quote}

This line of thinking suggests that the extent to which Vizmapper is not a tool limits the extent to which the principles of user interface and data visualization design ought to play a role in the design process. HCI is much better suited to evaluating more objective notions like utility, tasks, and functionality than more subjective notions like personality, quality of sound, and musical rapport.

It is clear from Tanaka's definitions that Vizmapper serves as a tool rather than an instrument. However, the fact that Vizmapper is specifically a tool for accomplishing the task of creating and modifying mappings \emph{within a musical instrument} suggests that the design must be treated more subtly in this particular context. As the purpose of Vizmapper is partly to make the connections between components in a musical instrument more malleable and more susceptible to experimentation for groups of non-programmers, the task bears some resemblance to a non-utilitarian task. It is reasonable to assume that if the evolution of an instrument is motivated by the quality of the sound that the instrument produces, then similarly the evolution of a mapping interface is motivated by the quality of the mappings and DMIs that the interface produces. This reality should be evaluating in parallel with the understanding that configuration of a mapping is a somewhat utilitarian task, either the interface allows a team to configure the mapping efficiently or it does not.

To see this, examine the task and to decompose the complex task of designing a musical instrument using an analysis process called \emph{hierarchical task analysis} \cite{annett1967}. 

Mark Marshall nicely distills the last decade of thinking into understanding the abstract components of a digital musical instruments by decomposing a digital musical instrument into 3 main components \cite{marshall2008}:

\begin{description}
\item \emph{The physical interface} containing the sensors, actuators, and physical body of the instrument.
\item \emph{The software synthesis system} which creates both the sonic output of the instrument and any visual, haptic and/or vibrotactile feedback.
\item \emph{The mapping system} in which connections are made between parameters of the physical interface and those of the synthesis system.
\end{description}

The design of these 3 components can be regarded as the 3 main subtasks of the overall task of designing a musical instrument. Each of these subtasks are themselves composed of more granular tasks, thus forming the beginnings of a hierarchical structure representing an analysis of the overall task.

\begin{description}
\item \emph{Designing the physical interface}
\begin{description}
\item choose sensors that are capable of detecting the desired physical phenomena or gestures
\item choose actuators that are capable of inducing the desired physical phenomena or feedback
\item choose sensors that are made available as outputs for connections to the inputs of the synthesis system
\item choose actuators that are made available as inputs for connections from the outputs of the synthesis system
\item choose structural/aesthetic materials that combined with the sensors and actuators will form the composite form of the physical interface
\item design the shape of the composite physical interface
\end{description}
\item \emph{Designing the software audio synthesis system}
\begin{description}
\item choose mechanism/algorithm for performing sound synthesis in software
\item choose mechanism/algorithm for generating visual, haptic, and/or vibrotactile feedback
\item choose parameters of sound synthesis that are made available as inputs for connections from the outputs of the physical interface and/or other components of the composite synthesis system
\item choose parameters of visual, haptic, and/or vibrotactile feedback synthesis that are made available as inputs for connections from the outputs of the physical interface and/or other components of the composite synthesis system
\item choose parameters of sound, visual, haptic, and/or vibrotactile synthesis that are made available as outputs for connections to the physical interface and/or other components of the synthesis system
\end{description}
\item \emph{Designing the mapping}
\begin{description}
	\item choose a subset from the complete set of available outputs to start connections from
	\item choose a subset from the complete set of available inputs to connect to specific outputs
	\item create functional transformation mappings that specify how (if at all) to modify source signals from outputs to generate the desired destination signals for the inputs
\end{description}
\end{description}

This hierarchical model of musical instrument design generalizes well to anything from a self-contained handheld instrument to a massively distributed system spread over a large physical environment. It also works regardless of whether it is an individual or a team that is engaged in the instrument design. This decomposition also makes more clear why perhaps the mapping system is deserving of a dedicated system and user interface to manipulate. 

A good analogy is the choice of what collection of LEGO blocks to use as opposed to how to put the LEGO blocks together once the blocks are chosen. Procedurally, one chooses what types of blocks to use before deciding how to put the blocks together. Similarly, it makes sense to make certain choices about what pieces will be used for the physical interface and the software synthesis system before deciding how the mapping system will put the two collections of inputs/outputs together. It is difficult to map between two sets of signals when the sets of signals are not already defined. Of course, this model laying out the necessary choices to be made says nothing about \emph{what} choices should be made. That process is entirely dependent on the artistic intentions of the design team and the goal of a mapping tool is only to allow the choices that are made in the mapping subtask to be implemented as efficiently as possible.

\section{System Design}

As a piece of software, there are a limited number of options for implementing the system while ensuring that the system can be reliably used on the variety of systems that a team designing a musical system is likely to be using in the present and future. As of the time that this system has been implemented, the most common form factors for computers are desktops, laptops, tablets, and smartphones. Each form factor is typically loaded with one of a small collection of operating systems that are widely available and are easy to find expert knowledge about.

\begin{description}
\item[Desktops/Laptops] Windows (XP, Vista, 7), Mac OSX, Linux (Ubuntu, Debian, etc.)
\item[Tablets/Smartphones] Android, iOS
\end{description}

This is not an exhaustive list, however the point is that it is not practical (especially in a research context) to develop and maintain several versions of a software system that will work on a wide variety of operating systems and devices. However, the fact is that people will use whatever system they have available and the variety of devices that an artist or engineer is likely to use to interact with a sensor network is increasing. To design a practical system that is meant to work in a collaborative context, it is crucial to adapt to this reality.

Before beginning development on a software system, it is necessary to choose a development environment and a deployment environment.

There are a number of terms that are used in the remainder of the chapter that are helpful to define. The specifics of the definitions are debatable, however they remain helpful for understanding the rest of this chapter.

\begin{description}
\item[Development environment] the sofware/hardware environment that the developer uses to write programmer code and executables
\item[Deployment environment] the software/hardware environment that the user uses to run executables
\item[Operating system] a program that manages hardware resources and the computer processor - from the developer's point of view, reduces the complexity and risk of writting programmer code that interfaces with the physical hardware and computer processor by providing an easier to use set of operations that provide a higher level interface (called system calls) to the processor and other hardware - system calls prevent programmer code from generating machine code that executes low-level processor and hardware operations in such a way that would destablize the system
\item[Progammer code] the human readable text that is written by the developer in a specific computer language and translated to produce an executable
\item[Machine code] the machine readable code that is often produced by a compiler and requires no further translation to be understood by a physical computer processor
\item[Executable] the file or collection of files that the user can \emph{run} without any further manual translation within their deployment environment - can be programmer code, machine code, or other forms of executable code  
\item[Machine] the physical computer processor that provides a stable interface of machine operations that can be executed by machine code
\item[Compiler] the software program that takes programmer code as input and produces machine code or machine code executables as output
\item[Interpretor] the software program takes programmer code as an executable to run a program
\end{description}

There are any number of very stable development environments that enable a software developer to write a single collection of programmer code and translate the code into executables that can run on Windows, OSX, and Linux machines. This choices effects the developer of the software and not the user of the software. The choice of deployment environment is much more consequential to the user because it effects how they will actually run the executable.

There are three common methods for a user to run software on their chosen machine.

\begin{enumerate}
\item The first method is for the user to run a compiled machine code executable, which means that the developer has written code and translated the code with a compiler into machine code that can be executed without any further translation on the user's specific machine and operating system. If there is no available compiled executable for a specific machine architecture, the user can obtain the programmer code and compile it into an executable that works on their specific machine as long as a compiler exists for their machine.

\item The first method is an option when the software is developed in a \emph{compiled language} environment. There are also environments that use \emph{interpreted languages} or \emph{script languages}. An interpreted language differs from a compiled language because unlike a compiled language that uses the process of translating the program code into machine code with a compiler and producing a machine code executable to run the program, an interpreted language uses the process of interpreting the program code line by line directly when the program is run. The interpretor is responsible for interfacing with the machine for the interpreted code when the executable is run. In a interpreted language the programmer code and the executable are often the same file. A compiled executable interfaces directly with the machine because it has already been converted into machine code. 

A web application is essentially an interpreted executable because a web browser that runs HTML, CSS, and Javascript downloads the programmer code and uses an internal interpretor to execute the program. It does not download a compiled executable. Distributing software as a script executable to be run in an interpretor is attractive because the burden for implementing the interpretor for various different machine architectures is moved to the developer of the programming language and the developer can count on a user being able to run their program as long as the interpretor for the language is available for the user's machine. The developer can write \emph{machine-independent} code.

\item Environments like Java use a third strategy and run software on \emph{virtual machines}. A virtual machine language is somewhat like a hybrid of a compiled language and interpreted language because a virtual machine language is compiled, but it is compiled to an intermediate machine code that is not the machine code of the actual physical machine that is running the program. It is compiled to the "machine code" of a software virtual machine that must be implemented for all machines that one would like to run the program on. This is useful because the user can be given a single file that is not program code like a compiled language, but the developer still can count on the file being able to be run on any machine that has the virtual machine available on the system.
\end{enumerate}

Assuming the intent is for multiple team members to be running the Vizmapper interface to enable simultaneous work on the mapping of a network and that there is presumably a local network available to allow the various devices on the sensor network to communicate with each other, suggests Vizmapper ought to be implemented as a web application. 

A web application is typically distributed as a two part software system where one part is called the \emph{client} and the other part is called the \emph{server}. One server can serve the web application to a large number of clients. This is the source of another advantage of web applications. A web client runs in a web browser and therefore can be run on any machine that includes a modern web browser. All modern web browsers provide an increasingly identical deployment environment. Since Libmapper is compiled code, the server software can take care of interfacing with the library and communicating through the Mapper Protocol with the rest of the network. Despite the fact that the server is more restricted as to what deployment environment it can be run on because of the Libmapper dependency, the server needs to run on only one machine. Also, a web application is much easier to deploy on a collection of heterogenous machines.

Stephen Sinclair, the developer of Libmapper and a member of IDMIL, also developed a basic server written in Python (a popular interpreted language) that interfaces with Libmapper and provides a convenient interface for a web browser client to indirectly speak the Mapper Protocol to the local network of devices by communicating with the server. This web server is called Webmapper. Together, Webmapper/Vizmapper provides a server/client web application that can be used to configure a Mapper network.

\section{Application of User Interface Design Principles}

If the user of Vizmapper is a human user configuring an MSN, then Vizmapper is the "user" of Webmapper. Webmapper is then the "user" of Libmapper. Libmapper provides an interface for Webmapper to speak the Mapper Protocol and Webmapper provides an interface for Vizmapper to indirectly speak the Mapper Protocol. Now the task remains to decide how the Vizmapper interface will present the signals and devices present on the network to the human user and allow the user to configure mappings between these signals and devices through Webmapper.

As a reminder, the subtask of \emph{Designing the Mapping} was further broken down as follows:

\begin{description}
	\item choose a collection of available outputs to start connections from
	\item choose a collection of available inputs to connect to specific outputs
	\item create mappings that specify how (if at all) to modify source signals from outputs to generate the desired destination signals for the inputs
\end{description}

The task of designing a mapping is a less complex task (but not less important) than the task of designing a physical interface or designing an audio synthesis system. This lack of complexity in the task is one of the reasons why it is possible to even contemplate performing the other task through a single interface. Building an interface for the task of designing a physical interface or designing an audio synthesis system is less manageable in this way.

Instead, the complexity of the task lies in the complexity of the Mapper network and what the task of \emph{choosing} actually entails. Since the focus is now on the mapping task, it is helpful to see if it is possible to be even more granular in the hierarchical decomposition of the task. 

\begin{description}
	\item choose a collection of available outputs to start connections from
    \begin{description}
        \item view the complete set of output signals
        \item find an output signal to connect to an input signal
        \item select the output signal
    \end{description}
	\item choose a collection of available inputs to connect to specific outputs
    \begin{description}
        \item view the complete set of input signals
        \item find an input signal to connect to an output signal
        \item select the input signal
    \end{description}
	\item create mappings that specify how (if at all) to modify source signals from outputs to generate the desired destination signals for the inputs
    \begin{description}
        \item define a functional transformation/signal conditioning mapping between the output signal and input signal 
        \item connect the signals
    \end{description}
\end{description}

This clarifies the individual steps implicit in the overall task and suggests how to distribute the steps needed in the interface. Since the screen space on a monitor is limited and the most important data about the Mapper network are the names of the signals and the mappings between them, devoting as much space to the visualization of the signals and their connections is a priority.

The first decision made is to separate the viewing and browsing of the MSN from the editing of mappings. Vizmapper treats these two set of subtasks as two different modes. Entering viewing and browsing mode means that it is not possible to modify the mappings of the signals being browsed. Entering editing mode focusing the view on a subset of signals from the complete set and means that it is not possible to browse the larger set of signals. This decision is made because viewing and browsing does not actually effect the Mapper network, only editing a mapping effects the network. Preventing both modes from being accessed on the same screen makes the conceptual separation between the modes clear and reduces the amount of accidental modifications.

When it comes to viewing and browsing, since the interface is being designed with larger MSNs in mind, there should be a way to filter the complete set of signals to a subset of signals. As discussed in chapter 3, this can be accomplished with pointing and clicking to utilize recognition processes or it can be accomplished by typing to encourage the use of recall processes. Although finding a specific signal through name recognition is less straining then remembering the name of a specific signal and typing it, it is not necessarily a simple decision. In the case where a user has been working with the same Mapper network for an extended period of time, it may become tedious to point, click, and browse their way to a specific signal even though they know the exact name of the signal they are looking for. In this case, the physical process involved to select the signal becomes more consciously cumbersome than the cognitive process involved in recognition or recall.

A single text input box for entering a text matching filter query, occupies very little vertical space and adds functionality that is helpful for this type of user. The user can type in a portion of the complete OSC name of a signal and limit the view to only the signals that match the text in the input box. In order to display the union of more than one text query (show the signals that match the first text query OR second query OR third query, etc.), the user uses a space character to delimit the separate filter queries. 

Typically, interfaces that allow the user to browse data using text queries allow the user to compose more complex queries (like ANDs or NOTs in addition to ORs). However, this functionality seems to deviate from the scope of the interface and add syntax complexity without a substantial benefit to the central task. Since the user is only searching within a set names of signals and not a set of large text documents (like one might do with a database or the internet) it is likely a type of power that is not required for most users. Additional features and complexity are avoided in Vizmapper, unless the functionality that is added is significant to the mapping task as it has been analyzed.

\section{Application of Data Visualization Design Principles}

Following the graphical perception research in section \ref{sec:Graphical Perception} of chapter 3, before making decisions about the visualization of the network the data set of a Mapper network needs to be analyzed using the three stage process of Bertin.

This involves determining the \emph{components} in the data, the \emph{length} of each component, and the \emph{level of organization} (nominal, ordinal, or quantitative).

There are three easily distinguishable sets of data that a user concerns themselves with when mapping signals.

\begin{enumerate}
\item The set of signals on the Mapper network, which are defined as OSC names that are part of a hierarchical namespace
\item The set of associative connections between pairs of signals, each connection is defined by a source and a destination (the source of the data is typically an output signal and the destination is typically an input signal)
\item The set of function transformations that are paired with each associative connection, which are defined using a function type, a mathematical function, and an allowable range of values for the input of the function (actually an output signal in Mapper terminology) and output of the function (actually an input signal in Mapper terminology).
\end{enumerate}

It is useful to note that the most complex elements are the elements of the set of functional transformations. The least complex elements are the OSC names of the signals. This is taken simply from the number of variables that must be defined to fully define each element.

So the data set can be decomposed into \emph{three} components, but it might also be decomposed into \emph{four}. The first component, the set of signals, can be split into one component for output signals and one component for input signals. The question is whether one decomposition is more effective than the other. If it is assumed that the source of a connection will always be an output signal of a device and the destination of a connection will always be an input signal of a device then it makes sense to use \emph{four} because it will always be necessary to select a source and a destination to form any connection and it will be efficient to graphically distinguish between the two types of signal. Therefore, there are \emph{four} components in the data set.

\begin{enumerate}
\item The set of output signals on the Mapper network, which are defined as OSC names that are part of a hierarchical namespace
\item The set of input signals on the Mapper network, which are defined as OSC names that are part of a hierarchical namespace
\item The set of associative connections between pairs of signals, each connection is defined by a source and a destination (the source of the data is typically an output signal and the destination is typically an input signal)
\item The set of function transformations that are paired with each associative connection, which are defined using a function type, a mathematical function, and an allowable range of values for the input of the function (actually an output signal in Mapper terminology) and output of the function (actually an input signal in Mapper terminology).
\end{enumerate}

The length of the output signals component and the input signals component are assumed to be \emph{large} and within an order of magnitude of each other. There might be many more output signals than input signals or vice versa, however since there will be roughly one control mechanism device with output signals for each sound generation mechanism device with input signals in a scenario with DMIs, this is a reasonable assumption.

The length of the set of associative connections is bounded by the length of the set of output signals. This is because the Mapper protocol only handles \emph{one-to-many} and \emph{one-to-one} mappings as explained in chapter 2. Therefore, there can be at most one connection for every output signal.

The length of the set of function transformations is equal to the length of the set of associative connections because there every connection is paired with a functional transformation governing data transmission over the connection.

\cite{edgebundles2006}
